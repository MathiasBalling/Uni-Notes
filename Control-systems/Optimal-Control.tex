\section{Integral Control and Optimal Control}

\subsection{Integral Control}
\subsection{Anti-windup}
Must always be applied when having an integrator in the controller.

\textbf {Designing Saturation Gain}

Dynamics of controller during saturation
$$ \dot{\hat{x}} = (A+LC+MF)\hat{x}$$
Determining M can be recognized as an observer gain design problem:
$$ \dot{\hat{x}} = (\tilde{A}+\tilde{L}\tilde{C}) \hat{x}$$

With $\tilde{A}=A+LC, \tilde{L}=M, \tilde{C}=F$. From which the unknown $\tilde{L}=M$ can be chosen to assign
any desired poles to the saturated controller.

\subsection{Optimal Control}

Consider a linear control system of the form:
$$ \dot{x} = Ax + Bu, x(0)=x_0 $$
$$ y = Cx $$

A control law for such a system is said to be optimal, if it minimizes the cost functional:

$$ J = \int_{0}^{\infty} (x^TQx + u^TRu) dt $$
Where $Q=Q^T$ is a positive semi-definite matrix (eigenvalues larger than or equal to 0) and $R=R^T$ is a positive definite matrices.

Algebraic Riccati Equation is a second order matrix equation in an indeterminate $P=P^T \in \mathbb{R}^{n \times n}$:
$$ A^TP + PA - PBR^{-1}B^TP + Q = 0 $$

P is called a stabilizing solution to the ARE, if it satisfies the equation, and further satisfies that the eigenvalues of
$A-BR^{-1}B^TP$ have negative real parts.

The optimal state feedback law is given by:
$$u = Fx$$
Where F is given by:
$F = -R^{-1}B^TP$


\subsection{Examples}
